{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b330e9-dece-4730-ba18-b716deae8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import butter, filtfilt, find_peaks\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e131c-504a-4aa8-913f-4289d6825d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquisition of data\n",
    "# Need to do some file sifting bc of incosistent naming\n",
    "file_data = {\"Filename\":[], \"DataType\":[], \"Condition\":[], \"Context\":[], \"Timepoint\":[],  \"Subject\":[]}\n",
    "folder = \"collected_data\"\n",
    "files = os.listdir(folder)\n",
    "\n",
    "for file in files:\n",
    "    if os.path.isdir(os.path.join(folder, file)):\n",
    "        continue\n",
    "    if \".DS_Store\" in file:  # Check if the file is a .DS_Store file (unwanted system file)\n",
    "        print(f\"Skipping system file: {file}\")\n",
    "        continue  # Skip this iteration and move to the next file\n",
    "    \n",
    "    # assign each file to a data type\n",
    "    if (\"DLC\" in file) and (\"filtered\" in file):\n",
    "        data_type = \"dlc\"\n",
    "    elif (\"DeepCut\" in file) and (\"filter\" not in file):\n",
    "        data_type = \"dlc_unfiltered\"\n",
    "    elif \"alldata\" in file:\n",
    "        data_type = \"photometry\"\n",
    "    else:\n",
    "        data_type = \"video_timestamps\"\n",
    "    \n",
    "    # get the group name, context, and test time point\n",
    "    if (\"CON\" in file) or (\"Con\" in file):\n",
    "        condition = \"con\"  # control\n",
    "    elif \"Run\" in file:\n",
    "        condition = \"run\"  # running\n",
    "    elif \"IRR\" in file:\n",
    "        condition = \"irr\"  # irradiation\n",
    "    else:\n",
    "        raise(NameError)\n",
    "    \n",
    "    if (\"empty\" in file):\n",
    "        context = \"homecage\"\n",
    "    elif \"A\" in file:\n",
    "        context = \"A\"\n",
    "    elif (\"B\" in file) and ~(\"empty\" in file):\n",
    "        context = \"B\"\n",
    "    else:\n",
    "        raise(NameError)\n",
    "    \n",
    "    if (\"recent\" in file) or (\"Recent\" in file):\n",
    "        timepoint = \"recent\"\n",
    "    elif (\"inter\" in file) or (\"Inter\" in file):\n",
    "        timepoint = \"inter\"\n",
    "    elif (\"remote\" in file) or (\"Remote\" in file):\n",
    "        timepoint = \"remote\"\n",
    "    else:\n",
    "        raise(NameError)\n",
    "\n",
    "    for n in range(1,20):\n",
    "        subject_tag = f\"M{n}\"\n",
    "        if subject_tag in file:\n",
    "            subject = subject_tag\n",
    "\n",
    "    file_data[\"Filename\"].append(os.path.join(folder, file))\n",
    "    file_data[\"DataType\"].append(data_type)\n",
    "    file_data[\"Condition\"].append(condition)\n",
    "    file_data[\"Context\"].append(context)\n",
    "    file_data[\"Timepoint\"].append(timepoint)\n",
    "    file_data[\"Subject\"].append(subject)\n",
    "\n",
    "file_df = pd.DataFrame(file_data)\n",
    "pd.set_option('display.max_rows', None)\n",
    "file_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d9f6a-9b37-4365-9e27-b4e62d74ac77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak extraction\n",
    "def filter_channel_data(pd_data, led_state, region=\"Region0G\", sigma=1.):\n",
    "    led_state = str(led_state)\n",
    "    channel = pd_data.query(\"LedState=={}\".format(led_state))[region].values\n",
    "    ch_ts = pd_data.query(\"LedState=={}\".format(led_state))[\"Timestamp\"].values\n",
    "    f_ch = interp1d(ch_ts, channel, fill_value=\"extrapolate\")\n",
    "    ch_interp = f_ch(ts)\n",
    "    return gaussian_filter1d(ch_interp, sigma)\n",
    "\n",
    "# specify mouse ID\n",
    "condition = \"con\"\n",
    "timepoint = \"recent\"\n",
    "subject = \"M1\"\n",
    "fs = 10\n",
    "\n",
    "for context in [\"homecage\", \"A\", \"B\"]:\n",
    "    session_files = file_df.query(\"Condition == @condition and Context == @context and Timepoint == @timepoint and Subject == @subject\")\n",
    "\n",
    "    photometry_file = session_files.query(\"DataType == 'photometry'\")[\"Filename\"].values[0]\n",
    "    data = pd.read_csv(photometry_file)\n",
    "    ts = np.arange(data[\"Timestamp\"][0], data[\"Timestamp\"].values[-1], 1/fs)\n",
    "    \n",
    "    # filter the original photometry data in each channel\n",
    "    ch1_interp = filter_channel_data(data, led_state=1)\n",
    "    ch2_interp = filter_channel_data(data, led_state=2)\n",
    "        \n",
    "    # apply the Butterworth high-pass filter to the normalized data within a given time window\n",
    "    ts, ch1_interp, ch2_interp = ts[start*fs:end*fs], ch1_interp[start*fs:end*fs], ch2_interp[start*fs:end*fs]\n",
    "    ts_rel = ts - ts[0]\n",
    "    b, a = butter(2, 0.05, btype=\"high\", fs=10)\n",
    "    norm = filtfilt(b, a, (ch2_interp - ch1_interp) / ch1_interp)\n",
    "\n",
    "    # peak extraction\n",
    "    mad = np.median(np.abs(norm - np.median(norm)))\n",
    "    thresh1 = np.median(norm) + 2*mad\n",
    "\n",
    "    point_under_thresh = norm[norm < thresh1]\n",
    "    mad2 = np.median(np.abs(point_under_thresh - np.median(point_under_thresh)))\n",
    "    thresh2 = np.median(point_under_thresh) + 2*mad2\n",
    "\n",
    "    norm_smooth = gaussian_filter1d(norm, 10)\n",
    "    peaks, peak_data = find_peaks(norm_smooth, height=thresh2)\n",
    "    \n",
    "    # visualization\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(norm, color='#999998', linewidth=1)\n",
    "    plt.axhline(thresh2, ls=\"--\", c=\"red\")\n",
    "    plt.scatter(peaks, norm.max()*np.ones(len(peaks)), c=\"red\")\n",
    "    plt.title(f\"{condition, subject, timepoint, context}\")\n",
    "\n",
    "    #Peak count\n",
    "    peak_count = len(peaks)\n",
    "    print(\"Number of peaks:\", peak_count)\n",
    "    print(2*mad2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c1244-54b8-46ca-ba13-cbe868683e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def onset_offset(vect):\n",
    "      onsets = np.argwhere([(vect[t]==0) & (vect[t+1]==1) for t in range(len(vect)-1)]).ravel()\n",
    "      offsets = np.argwhere([(vect[t]==1) & (vect[t+1]==0) for t in range(len(vect)-1)]).ravel()\n",
    "      return onsets, offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587e8732-5c25-4807-a333-a35e185163e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bout extraction\n",
    "condition = 'con'\n",
    "\n",
    "fs = 10\n",
    "filt_sigma = 2.5\n",
    "contexts = file_df.Context.unique()\n",
    "timepoints = file_df.Timepoint.unique()\n",
    "mice = file_df.Subject.unique()\n",
    "\n",
    "window_size = np.array([-fs*9, fs*3]).astype(int)\n",
    "windows = np.array([]).reshape(0, window_size[1]-window_size[0])\n",
    "windows_motion = np.array([]).reshape(0, window_size[1]-window_size[0])\n",
    "time_index = np.arange(windows.shape[1])/fs + window_size[0]/fs\n",
    "\n",
    "results = {\"mouse\":[], \"context\":[], \"timepoint\":[], \"t\":[],  \"activity\":[], \"motion\":[]}\n",
    "results_freezing = {\"mouse\":[], \"context\":[], \"timepoint\":[], \"freezing\":[], \"condition\":[]}\n",
    "\n",
    "df_con = file_df.query(\"Condition == @condition\")\n",
    "for ix, (context, timepoint, mouse) in tqdm(enumerate(product( contexts, timepoints, mice))):\n",
    "    query_string = \"Context == @context and Timepoint == @timepoint and Subject == @mouse\"\n",
    "    session_files = df_con.query(query_string)\n",
    "    if len(session_files) == 0:\n",
    "        continue\n",
    "    print('processing {} {} {} {}...'.format(condition, timepoint, mouse, context))\n",
    "    \n",
    "    # read photometry data\n",
    "    photometry_file = session_files.query(\"DataType == 'photometry'\")[\"Filename\"].values[0]\n",
    "    data = pd.read_csv(photometry_file)\n",
    "    ts = np.arange(data[\"Timestamp\"][0], data[\"Timestamp\"].values[-1], 1/fs)\n",
    "    \n",
    "    # filter the original photometry data in each channel\n",
    "    ch1_interp = filter_channel_data(data, led_state=1, sigma=2.5)\n",
    "    ch2_interp = filter_channel_data(data, led_state=2, sigma=2.5)\n",
    "    norm = (ch2_interp - ch1_interp)/ch1_interp\n",
    "    \n",
    "    \n",
    "    # read DLC data\n",
    "    dlc_file = session_files.query(\"DataType == 'dlc'\")[\"Filename\"].values[0]\n",
    "    dlc_data = pd.read_csv(dlc_file, index_col=0)\n",
    "    \n",
    "    # interpolate all DLC data\n",
    "    try:\n",
    "        x_nose = dlc_data.iloc[2:,0].astype(float).values\n",
    "        y_nose = dlc_data.iloc[2:,1].astype(float).values\n",
    "        x_head = dlc_data.iloc[2:,3].astype(float).values\n",
    "        y_head = dlc_data.iloc[2:,4].astype(float).values\n",
    "        x_tail = dlc_data.iloc[2:,6].astype(float).values\n",
    "        y_tail = dlc_data.iloc[2:,7].astype(float).values\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    video_timestamp_file = session_files.query(\"DataType == 'video_timestamps'\")[\"Filename\"].values[0]\n",
    "    video_ts_data = pd.read_csv(video_timestamp_file, header=None)\n",
    "    video_ts = video_ts_data.iloc[:, 0].values\n",
    "    video_ts_rel = video_ts - video_ts[0]\n",
    "    # ts = np.arange(video_ts_rel[0], video_ts_rel[-1], 1/fs)\n",
    "    x_nose, y_nose, x_head, y_head, x_tail, y_tail = (x_nose[:len(video_ts)], y_nose[:len(video_ts)], \n",
    "                                                      x_head[:len(video_ts)], y_head[:len(video_ts)], \n",
    "                                                      x_tail[:len(video_ts)], y_tail[:len(video_ts)])\n",
    "    \n",
    "    # process DLC data to make coordinates\n",
    "    xy_list = [x_nose, y_nose, x_head, y_head, x_tail, y_tail]\n",
    "    coords = []\n",
    "    \n",
    "    for c in xy_list:\n",
    "        f_c = interp1d(video_ts, c, fill_value=\"extrapolate\")\n",
    "        c_interp = f_c(ts)\n",
    "        coords.append(c_interp)\n",
    "\n",
    "    coords = np.stack(coords)\n",
    "\n",
    "    coords = coords[:, start*fs:end*fs]\n",
    "    norm = norm[start*fs:end*fs]\n",
    "\n",
    "    b, a = butter(2, 0.01, btype=\"high\", fs=fs)\n",
    "    norm_filt = scale(filtfilt(b, a, norm))\n",
    "\n",
    "\n",
    "    # motion processing to detect freezing bouts\n",
    "    motion_raw = np.mean(np.abs(coords - np.roll(coords, 1, axis=1)), axis=0)\n",
    "    motion_raw[0] = 0\n",
    "    motion = gaussian_filter1d(motion_raw, filt_sigma)\n",
    "    motion_scale = scale(motion)\n",
    "\n",
    "    thresh = 0.005*np.median(np.sqrt((coords[0, :]-coords[4, :])**2 + (coords[1, :] - coords[5, :])**2))\n",
    "    freezing = (motion-motion.min()) < thresh\n",
    "\n",
    "    results_freezing[\"freezing\"].append(np.mean(freezing))\n",
    "    results_freezing[\"context\"].append(context)\n",
    "    results_freezing[\"timepoint\"].append(timepoint)\n",
    "    results_freezing[\"mouse\"].append(mouse)\n",
    "    results_freezing[\"condition\"].append(condition)\n",
    "\n",
    "    freezing_cleaned = freezing.copy()\n",
    "\n",
    "    onsets, offsets = onset_offset(freezing)\n",
    "\n",
    "    if onsets[0] > offsets[0]:\n",
    "        offsets = offsets[1:]\n",
    "\n",
    "    if freezing[-1] == 1:\n",
    "        onsets = onsets[:-1]\n",
    "    \n",
    "    # eliminate freezing/non-freezing bouts that are shorter than 1 second\n",
    "    for oo in range(len(onsets)):\n",
    "        if oo == len(onsets)-1:\n",
    "            break\n",
    "        if (offsets[oo] - onsets[oo]) < 1*fs:\n",
    "            freezing_cleaned[onsets[oo]:offsets[oo]+1] = 0\n",
    "        if (onsets[oo+1] - offsets[oo]) < 1*fs:\n",
    "            freezing_cleaned[offsets[oo]:onsets[oo+1]+1] = 1\n",
    "\n",
    "    onsets, offsets = onset_offset(freezing_cleaned)\n",
    "\n",
    "\n",
    "    # Add checks before creating arrays:\n",
    "    if len(onsets) > 1 and window_size[1] > window_size[0]:\n",
    "        windows = np.zeros((len(onsets) - 1, window_size[1] - window_size[0]))\n",
    "        windows_motion = np.zeros((len(onsets) - 1, window_size[1] - window_size[0]))\n",
    "    else:\n",
    "        print(\"Error: Invalid dimensions for array creation - len(onsets):\", len(onsets), \"window_size:\", window_size[1] - window_size[0])\n",
    "\n",
    "    # Assuming other parts of your code are correct and in place\n",
    "    for oo in range(len(onsets) - 1):\n",
    "        if (onsets[oo] + window_size[1] >= len(norm_filt)) or (onsets[oo] + window_size[0] <= 0):\n",
    "            continue\n",
    "\n",
    "    # Convert the relevant segment to a pandas Series to use diff()\n",
    "        window_segment = pd.Series(freezing[onsets[oo]:onsets[oo] + window_size[1]])\n",
    "        if any(window_segment.diff() == -1):\n",
    "            continue  # Skip this window if freezing ends\n",
    "\n",
    "    # If the segment is valid, perform your operations\n",
    "        windows[oo, :] = norm_filt[onsets[oo] + window_size[0]: onsets[oo] + window_size[1]]\n",
    "        windows_motion[oo, :] = motion[onsets[oo] + window_size[0]: onsets[oo] + window_size[1]]\n",
    "\n",
    "    # Handle overlaps and NaN assignments as previously coded\n",
    "        if oo > 0 and ((onsets[oo] + window_size[0]) < offsets[oo - 1]):\n",
    "            overlap = -window_size[0] - (onsets[oo] - offsets[oo - 1])\n",
    "            windows[oo, :overlap] = np.nan\n",
    "            windows_motion[oo, :overlap] = np.nan\n",
    "\n",
    "        if offsets[oo] < (onsets[oo] + window_size[1]):\n",
    "            overlap = (onsets[oo] + window_size[1]) - offsets[oo]\n",
    "            windows[oo, -overlap:] = np.nan\n",
    "            windows_motion[oo, -overlap:] = np.nan\n",
    "\n",
    "        if np.sum(~np.isnan(windows[oo, :])) < 10:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "    for oo in range(windows.shape[0]):\n",
    "        for t_index, time in enumerate(time_index):\n",
    "            results[\"t\"].append(time)\n",
    "            results[\"activity\"].append(windows[oo, t_index])\n",
    "            results[\"motion\"].append(windows_motion[oo, t_index])\n",
    "            results[\"context\"].append(context)\n",
    "            results[\"timepoint\"].append(timepoint)\n",
    "            results[\"mouse\"].append(mouse)\n",
    "            \n",
    "print('done')\n",
    "# print(results[\"motion\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
